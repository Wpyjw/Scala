| 管道符  用来连接多条命令的  命令1|命令2 用管道符连接的命令，命令 1 的正确输出作为命令 2 的操作对象

awk是一种可以处理数据、产生格式化报表的语言
awk “样式” 文件： 把符合样式的数据行显示出来。
awk { 操作 } 文件： 对每一行都执行{}中的操作。
awk " 样式 { 操作 }" 文件： 对符合样式的数据行，执行{}中的操作.

-i
若用-i参数，则bash是交互的。

-s
若用-s参数，则bash从标准输入中读入命令（在执行完-c带的命令之后。）直到输入exit。

$() ``都是用来作命令替换的 命令替换与变量替换差不多，都是用来重组命令行的，先完成引号里的命令行，然后将其结果替换出来，再重组成新的命令行。
$(命令) 返回该命令的结果

${} $var 变量替换
一般情况下，$var与${var}是没有区别的，但是用${ }会比较精确的界定变量名称的范围

# 是去掉左边(在键盘上 # 在 $ 之左边)
% 是去掉右边(在键盘上 % 在 $ 之右边)

bc命令是任意进度计算器语言，通常在linux下当计算器用
bc(选项)(参数)

$0 表示当前动行的命令名，一般用于shell 脚本中；
dirname 用于取指定路径所在的目录 ；如 dirname /usr/local/bin 结果为dirname /usr/local

source 使Shell读入指定的Shell程序文件并依次执行文件中的所有语句

#获取变量长度

S=${1:-2} if else


Spark部署
=========================================================================
Spark部署模式  local 单机模式  
              cluster 集群模式  stackalone  mesos   yarn 
              
                      yarn 
                          yarn cluster :这个就是生产环境常用的模式，所有的资源调度和计算都在集群环境上运行。
                          yarn client  :这个是说Spark Driver和ApplicationMaster进程均在本机运行，而计算任务在cluster上。
                          
                          
linux下如何执行文件


git流程
git已经配置好
1.开始->git->git bash
2.cd到要创建库的文件夹
3.git init 
4.登陆http://v9.git.n.xiaomi.com/  复制要下载的文件的地址
5.git clone wenjain dizhi

linux流程
直接git clone wenjian dizhi 
pwd 查看当前路径

mvn package 
sh -x lujingwenjian  日志

mvn pachage 完成打jar包的命令 构建项目软件包

RDD 弹性分布式数据集
不可变、可分区、里面的元素可并行计算的集合。
RDD 方法
map(func) 返回一个新的RDD，该RDD由每一个输入元素经过func函数转换后组成
flatMap(func) 类似于map，但是每一个输入元素可以被映射为0或多个输出元素（所以func应该返回一个序列，而不是单一元素）
join(otherDataset, [numTasks]) 在类型为(K,V)和(K,W)的RDD上调用，返回一个相同key对应的所有元素对在一起的(K,(V,W))的RDD  相当于内连接（求交集
cogroup(otherDataset, [numTasks]) 在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,(Iterable<V>,Iterable<W>))类型的RDD

RDD的属性 1 一组分片

's'字符串插值器允许在处理字符串时直接使用变量

--class: 应用入口类（例如：org.apache.spark.examples.SparkPi)）

hadoop fs -ls列出指定目录下的文件及文件夹
-du 显示目录中所有文件的大小，或者当只指定一个文件时，显示此文件的大小。

scala中=>
1.表示函数的返回类型
2.匿名函数
3.case语句
4.By-Name Parameters（传名参数）
闭包是一个函数，返回值依赖于声明在函数外部的一个或多个变量


Spark
Spark-Shell
val textFile = sc.textFile("README.md")
spark.RDD[String] = spark.MappedRDD@2ee9b6e3



RDDs支持2种类型的操作：
转换(transformations) 从已经存在的数据集中创建一个新的数据集；
  map 是一个转换操作，它将每一个数据集元素传递给一个函数并且返回一个新的 RDD。
动作(actions) 在数据集上进行计算之后返回一个值到驱动程序。
  reduce 是一个动作，它使用相同的函数来聚合 RDD 的所有元素，并且将最终的结果返回到驱动程序

样例类
使用了case关键字的类定义就是样例类，样例类是种特殊的类，经过优化以用于模式匹配。

scala Option(选项)类型用来表示一个值是可选的（有值或无值）
Option[T]是一个类型为T的可选值的容器：如果值存在，Option[T]就是一个Some[T],如果不存在，Option[T]就是对象None。

Scala
类名称 第一个字母应为大写。。如果使用多个单词来形成类的名称，则每个内部单词的第一个字母应该是大写。
方法名称 - 所有方法名称应以小写字母开头。如果使用多个单词形成方法的名称，则每个内部单词的第一个字母应为大写。

语法
var myVar:String="Foo"
val myVal:String="Foo"

多个赋值 如果代码块或方法返回一个元组，则可以将元组分配给一个val变量。
val (myVar1:Int,myVar2:String)=Pair(40,"Foo")
函数声明  def functionName ([list of parameters]) : [return type]
如果不使用等号和方法体，则隐式声明抽象方法

函数定义
def functionName ([list of parameters]): [return type]={
  function body
  return [expr]
}

def shadoubufanhui(): Unit{

}

调用方法
functionName(list of parameters)
[instance.]functionName( list of parameters )

匿名函数 (x: Int)=>x+1
函数文字，在运行时，函数文字被实例化成为函数值的对象
var inc= (x:Int)=>x+1
var x=inc(7)-1
var mul=(x:Int,y:Int)=>x*y
var userDir = () => { System.getProperty("user.dir") }

字符串
var greeting="Hello World";

var palindrome = "Dot saw I was Tod";
var len = palindrome.length();
声明数组变量
var z:Array[String]=new Array[String](3)
var z=new Array[String](3)
z(0)="3"
定义数组的方法 var z = Array("Maxsu", "Nancy", "Alen")

Scala元组 元组可以容纳不同类型的对象，但它们也是不可变的
val t=(1,"hello",Console)
val sum = t._1 + t._2 + t._3 + t._4
 Scala映射
声明不可变映射的示例声明
var A:Map[Char,Int]=Map()
var colors=Map("red"->"#FF00000","azure"->"#F0FFFF")



